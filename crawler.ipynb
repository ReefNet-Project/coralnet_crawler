{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    PA250025.JPG\n",
      "1    PA250026.JPG\n",
      "2    PA250027.JPG\n",
      "Name: Name, dtype: object\n",
      "Number of Images:  50\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('metadata.csv')\n",
    "imageList = df['Name']\n",
    "print(imageList[0:3])\n",
    "numImages = imageList.size\n",
    "print('Number of Images: ',numImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get images from coralnet website by parsing source code\n",
    "import re\n",
    "\n",
    "\n",
    "searchList = imageList\n",
    "k = 0 # number of images found\n",
    "baseURLnumber = 2105286\n",
    "runOnce = 0\n",
    "\n",
    "for n in range(numImages):\n",
    "    # luckily the images are stored on pages with numerically increasing paths\n",
    "    # url of first image: https://coralnet.ucsd.edu/image/134549/view/\n",
    "    # url of last image: https://coralnet.ucsd.edu/image/134938/view/\n",
    "    page_url = 'https://coralnet.ucsd.edu/image/' + str(baseURLnumber + n) + '/view/'\n",
    "    # grab the source code\n",
    "    r = requests.get(page_url)\n",
    "    source = r.text\n",
    "    # now search the source code for the images from our annotations list\n",
    "    # we remove the image from the search list once we find it,\n",
    "    # so the size of searchList should reduce as n increases\n",
    "    for i, name in enumerate(searchList):\n",
    "        if source.find(name) > 0:\n",
    "            # we found the image name. Now find the image download URL, based on some sleuthing of the HTML.\n",
    "            # it should contain a Signature, Expiration, and AWSAccessKeyId\n",
    "            img_url = re.search(r'coralnet-production.s3.us-west-2.amazonaws.com(.*?)>', source).group(1)\n",
    "            url = 'https://coralnet-production.s3.us-west-2.amazonaws.com' + img_url\n",
    "            # fix some formatting\n",
    "            url = url.replace('&amp;', '&')\n",
    "            url = url.replace('\" /', '')\n",
    "            # now get the image from the URL\n",
    "            r = requests.get(url, allow_redirects=True)\n",
    "            # write it to a local file\n",
    "            open(name, 'wb').write(r.content)\n",
    "            # remove that name from searchList so we don't search for it again\n",
    "            searchList.drop(searchList.index[i])\n",
    "            # increment the number of images we have found\n",
    "            k = k + 1\n",
    "    if runOnce == 1:\n",
    "        break\n",
    "print('found', k, 'images.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
